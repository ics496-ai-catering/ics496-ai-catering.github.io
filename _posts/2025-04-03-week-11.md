---
title: Week 11 - Data Analysis & Cleansing for ALS Recommender
date: 2024-04-03
categories: [weekly_meeting]
tags: []
---

### 1. Dataset Inspection

* Began with the pre‑processed dump of catering requests (2017–early 2020) and the associated menu items.
* Discovered anomalies:

  * **Party‑size** field contained a “–20” entry and numerous zeros/NaNs.
  * One record’s columns had shifted (data spilling into row 631).
  * Several columns (dates, addresses, view counts, special accommodations) were irrelevant for recommendations.

---

### 2. Cleaning & Normalization Steps

1. **Pruned unnecessary fields**

   * Removed metadata columns (`cateringdate`, `date`, `address`, `viewed`, `archived`, `special‑accommodations`) to focus on core features.
2. **Standardized text inputs**

   * Stripped whitespace and lowercased all string fields for consistency.
3. **Harmonized party‑size**

   * Merged `party‑size` with `custom‑party‑size`: any non‑zero custom value overwrote the original.
   * Treated “Other Specified,” zeros, and NaNs as custom sizes; flagged true zeros for manual review.
4. **Matched preset menus**

   * Loaded `preset_menus.csv` and joined on menu ID, dropping mismatched IDs after logging them.
5. **Budget processing**

   * Coded “negotiable” budgets as NaN, set true NaNs to –1 (“no budget provided”).
   * Converted range strings (`"50-100"`, `"<200"`, `"500+"`) into numeric midpoints.
   * Trained a simple linear regression on valid rows (budget vs. party‑size) to impute missing budgets.
6. **Service encoding**

   * One‑hot‑encoded the “services” field (staff, delivery, entertainment, tent) by splitting on delimiters and filling blanks.

---

### 3. Feature‑Engineering Outcomes

* Produced a clean DataFrame (`df6`/`df7`) ready for model input:

  * Numeric `party‑size` and `budget` columns with no NaNs.
  * Categorical features (menu ID, services) properly encoded.
* Logged and removed outliers or unmatched menu references to ensure dataset integrity.

---

### 4. Next Steps

1. **Database import**: Load the cleaned tables into PostgreSQL via our Next.js API for downstream use.
2. **ALS model training**: Use the processed request history to fit the collaborative‑filtering recommender.
3. **Evaluation**: Split by time (pre‑2020 vs. 2020+) to validate recommendation performance on held‑out events.
4. **Incorporate additional signals**: Merge event types, location distance, and budget tiers to refine personalization.
